{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80e818b",
   "metadata": {},
   "source": [
    "# Advanced RAG 시스템 구현 강의자료\n",
    "\n",
    "## 1. Multi-Query RAG 기법 소개\n",
    "\n",
    "Multi-Query RAG는 하나의 질문을 여러 형태로 변환하여 더 포괄적인 검색을 수행하는 기법입니다.\n",
    "\n",
    "### 기본 원리\n",
    "\n",
    "\n",
    "원본 질문 → 7개의 변형 질문 생성 → 각각 검색 → 중복 제거 → Context Compression → 답변\n",
    "\n",
    "### 장점\n",
    "\n",
    "- **검색 범위 확대**: 다양한 표현으로 더 많은 관련 문서 발견\n",
    "- **정확도 향상**: 단일 질문의 한계를 보완\n",
    "- **누락 최소화**: 동의어나 유사 표현 문서까지 검색\n",
    "- **노이즈 감소**: Context Compression으로 불필요한 정보 제거\n",
    "- **효율성 증대**: 압축으로 토큰 사용량 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb656cf",
   "metadata": {},
   "source": [
    "## 2. 필요한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed3b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate as LCPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eddbfc",
   "metadata": {},
   "source": [
    "## 3. 시스템 구성 요소\n",
    "\n",
    "### 3.1 벡터 데이터베이스  저장\n",
    "\n",
    "- 벡터 데이터베이스를 로컬에 저장하여 재사용 가능\n",
    "- 매번 임베딩을 다시 생성할 필요 없어 시간 절약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624bdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_PATH = \"faiss_index_MQ_RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e32199",
   "metadata": {},
   "source": [
    "### 3.2 벡터 DB 생성 함수\n",
    "\n",
    "- 청크 크기 1200자로 설정하여 충분한 컨텍스트 제공\n",
    "- 오버랩 200자로 정보 손실 방지\n",
    "- PDF 문서 직접 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223e2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db():\n",
    "    # PDF 문서 로딩\n",
    "    loader = PyPDFLoader(\"./document/원자력안전관리_설명자료.pdf\")\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # 문서 분할 (청크 크기: 1200, 오버랩: 200)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1200, \n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # 임베딩 및 벡터 저장소 생성\n",
    "    embeddings = OllamaEmbeddings(model=\"exaone3.5:7.8b\")\n",
    "    vector_store = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "    \n",
    "    # 로컬에 저장\n",
    "    vector_store.save_local(VECTOR_DB_PATH)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed66e2a",
   "metadata": {},
   "source": [
    "### 3.3 벡터 DB 로딩 또는 생성\n",
    "\n",
    "**장점:**\n",
    "- 첫 실행 후 빠른 시작 가능\n",
    "- 리소스 효율적 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3735f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 벡터 DB를 생성합니다.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(VECTOR_DB_PATH):\n",
    "    print(\"기존 벡터 DB를 로드합니다.\")\n",
    "    embeddings = OllamaEmbeddings(model=\"exaone3.5:7.8b\")\n",
    "    vector_store = FAISS.load_local(\n",
    "        VECTOR_DB_PATH,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    print(\"새로운 벡터 DB를 생성합니다.\")\n",
    "    vector_store = create_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3697bc",
   "metadata": {},
   "source": [
    "## 4. 프롬프트 설계\n",
    "\n",
    "### 4.1 QA 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6118592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = PromptTemplate.from_template(\n",
    "\"\"\"당신은 질문-답변(Question-Answering)을 수행하는 AI 어시스턴트입니다. \n",
    "당신의 임무는 주어진 문맥(context)에서 주어진 질문(question)에 답하는 것입니다.\n",
    "\n",
    "검색된 다음 문맥(context)을 사용하여 질문(question)에 답하세요. \n",
    "만약, 주어진 문맥(context)에서 답을 찾을 수 없다면, \n",
    "\"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다\"라고 답하세요.\n",
    "\n",
    "질문과 관련성이 높은 내용만 답변하고 추측된 내용을 생성하지 마세요. \n",
    "기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "#Question: {question}\n",
    "#Context: {context}\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c7b27",
   "metadata": {},
   "source": [
    "### 4.2 Multi-Query 생성 프롬프트\n",
    "\n",
    "**목적:**\n",
    "- 하나의 질문을 다양한 표현으로 변환\n",
    "- 검색 범위 확대로 더 많은 관련 문서 발견\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c13da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_prompt = LCPromptTemplate.from_template(\n",
    "\"\"\"주어진 사용자 질문의 다양한 버전을 생성하는 AI입니다.\n",
    "사용자의 질문을 paraphrasing해서 질문의 의도와 의미가 동일한 새로운 질문 7개를 만들어냅니다.\n",
    "질문 속 핵심 단어는 유지하고 조사나 수식어와 같은 부가적인 표현을 paraphrasing합니다.\n",
    "\n",
    "각 질문은 다음과 같은 다양한 표현 방식을 사용하세요:\n",
    "1. 정의를 묻는 형태\n",
    "2. 설명을 요청하는 형태  \n",
    "3. 구체적인 내용을 묻는 형태\n",
    "4. 절차나 과정을 묻는 형태\n",
    "5. 특징이나 특성을 묻는 형태\n",
    "6. 목적이나 이유를 묻는 형태\n",
    "7. 다른 용어로 표현한 형태\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "7가지 다양한 질문:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0bdef-c4cf-4a52-9429-fbb727d2af1a",
   "metadata": {},
   "source": [
    "Context Compression 프롬프트\n",
    "\n",
    "**목적:**\n",
    "- 검색된 여러 문서들에서 핵심 정보만 추출\n",
    "- 중복 내용 제거 및 노이즈 감소\n",
    "- 질문과 관련된 정보만 선별적으로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ee0e88-f407-4d2a-90f8-451e7b175cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_compression_prompt = LCPromptTemplate.from_template(\n",
    "\"\"\"당신은 문서 요약 전문가입니다. 주어진 여러 문서들에서 질문과 관련된 핵심 정보만을 추출하여 간결하게 요약해주세요.\n",
    "\n",
    "중복된 내용은 제거하고, 질문에 답하는데 필요한 가장 중요한 정보들만 포함하세요.\n",
    "요약된 내용은 원본의 의미를 보존하면서도 불필요한 세부사항은 제거해야 합니다.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "문서들:\n",
    "{documents}\n",
    "\n",
    "압축된 컨텍스트:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c124ac4",
   "metadata": {},
   "source": [
    "## 4.3 체인 및 Retriever 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c599af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = OllamaLLM(model=\"exaone3.5:7.8b\", temperature=0)\n",
    "\n",
    "# QA 체인 정의\n",
    "qa_chain = qa_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Context Compression 체인 정의\n",
    "compression_chain = context_compression_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Basic Retriever\n",
    "basic_retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a57f9",
   "metadata": {},
   "source": [
    "## 5. Advanced RAG 구현\n",
    "\n",
    "### 5.1 Multi-Query 생성 함수\n",
    "\n",
    "**핵심 특징:**\n",
    "- 7개의 다양한 변형 질문 생성\n",
    "- 번호나 특수문자 자동 제거\n",
    "- 품질 필터링으로 의미있는 질문만 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8c16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_queries(question, llm, num_queries=7):\n",
    "    \"\"\"여러 개의 변형 질문을 생성하는 함수\"\"\"\n",
    "    prompt_input = multi_query_prompt.format(question=question)\n",
    "    generated_text = llm.invoke(prompt_input)\n",
    "    \n",
    "    # 생성된 텍스트에서 질문들 추출\n",
    "    generated_queries = []\n",
    "    lines = generated_text.split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.endswith(\":\") and line != \"7가지 다양한 질문:\":\n",
    "            # 번호나 특수문자 제거\n",
    "            cleaned_line = line.lstrip(\"1234567890.-•*\").strip()\n",
    "            if cleaned_line and len(cleaned_line) > 10:  # 너무 짧은 텍스트 제외\n",
    "                generated_queries.append(cleaned_line)\n",
    "    \n",
    "    # 최대 num_queries개까지만 반환\n",
    "    return generated_queries[:num_queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce38c4d-7497-4033-8bab-ab1ee7bd91c9",
   "metadata": {},
   "source": [
    "### 5.2 Context Compression 함수\n",
    "\n",
    "**핵심 특징:**\n",
    "- 여러 문서를 하나로 결합\n",
    "- LLM을 통한 지능적 압축\n",
    "- 원본 의미 보존하면서 노이즈 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87ded79-3d31-4dc4-b98f-7293d8953066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_context(question, documents, llm):\n",
    "    \"\"\"검색된 문서들을 압축하는 함수\"\"\"\n",
    "    if not documents:\n",
    "        return \"\"\n",
    "    \n",
    "    # 문서들을 하나의 텍스트로 결합\n",
    "    combined_docs = \"\\n\\n---문서구분---\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    # 컨텍스트 압축 실행\n",
    "    compressed_context = compression_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"documents\": combined_docs\n",
    "    })\n",
    "    \n",
    "    return compressed_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc5533-6287-4ee3-90dd-61fc9074bb80",
   "metadata": {},
   "source": [
    "### 5.3 Advanced 질문 생성 및 검색 함수\n",
    "\n",
    "**핵심 특징:**\n",
    "- Multi-Query 접근법으로 검색 품질 향상\n",
    "- 중복 제거로 효율성 증대\n",
    "- Context Compression으로 노이즈 감소\n",
    "- 예외 처리로 안정성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a88a42-5e1f-4490-b18b-71cdc439f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_advanced_context_with_compression(question, llm, vector_store, num_queries=7):\n",
    "    \"\"\"개선된 Multi-Query RAG with Context Compression\"\"\"\n",
    "    \n",
    "    # 1. 여러 변형 질문 생성\n",
    "    generated_queries = generate_multiple_queries(question, llm, num_queries)\n",
    "    \n",
    "    print(f\"\\n[생성된 {len(generated_queries)}개의 변형 질문들]\")\n",
    "    for i, q in enumerate(generated_queries, 1):\n",
    "        print(f\"{i}. {q}\")\n",
    "    \n",
    "    # 2. 각 질문으로 검색 후 통합\n",
    "    print(f\"\\n[Multi-Query 검색 실행]\")\n",
    "    all_docs = []\n",
    "    for i, q in enumerate(generated_queries, 1):\n",
    "        search_results = vector_store.similarity_search(q, k=3)  # 각 쿼리당 최대 3개 문서\n",
    "        if search_results:\n",
    "            all_docs.extend(search_results)\n",
    "            print(f\"질문 {i}: {len(search_results)}개 문서 검색됨\")\n",
    "    \n",
    "    # 3. 중복 문서 제거\n",
    "    unique_docs = []\n",
    "    seen = set()\n",
    "    for doc in all_docs:\n",
    "        if doc.page_content not in seen:\n",
    "            unique_docs.append(doc)\n",
    "            seen.add(doc.page_content)\n",
    "    \n",
    "    print(f\"총 {len(all_docs)}개 문서 검색, 중복 제거 후 {len(unique_docs)}개 고유 문서\")\n",
    "    \n",
    "    # 4. Context Compression 적용\n",
    "    if unique_docs:\n",
    "        print(\"\\n[Context Compression 실행 중...]\")\n",
    "        original_length = len(''.join([doc.page_content for doc in unique_docs]))\n",
    "        compressed_context = compress_context(question, unique_docs, llm)\n",
    "        compressed_length = len(compressed_context)\n",
    "        \n",
    "        compression_ratio = round((1 - compressed_length/original_length) * 100, 1) if original_length > 0 else 0\n",
    "        print(f\"압축 완료: {original_length} → {compressed_length} 문자 (압축률: {compression_ratio}%)\")\n",
    "        return compressed_context\n",
    "    else:\n",
    "        print(\"관련 문서를 찾을 수 없습니다.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b479d4d",
   "metadata": {},
   "source": [
    "# 6. Basic RAG vs Advanced RAG with Compression 비교\n",
    "\n",
    "### 6.1 Basic RAG\n",
    "\n",
    "**특징:**\n",
    "- 빠른 검색 속도\n",
    "- 단순한 구조\n",
    "- 제한적인 검색 범위\n",
    "- 단일 질문으로만 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594f13f",
   "metadata": {},
   "source": [
    "### 6.2 Multi-Query RAG with Context Compression\n",
    "\n",
    "**특징:**\n",
    "- 더 포괄적인 검색 (7개 변형 질문)\n",
    "- 높은 정확도\n",
    "- Context Compression으로 노이즈 제거\n",
    "- 효율적인 토큰 사용\n",
    "- 다소 느린 속도 (LLM 호출 추가)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a59866-f429-45a3-9f05-69522bbaa943",
   "metadata": {},
   "source": [
    "### 6.3 성능 개선 효과\n",
    "\n",
    "**검색 품질:**\n",
    "- 7개 변형 질문으로 검색 범위 확대\n",
    "- 동의어, 유사 표현까지 포괄하는 검색\n",
    "\n",
    "**효율성:**\n",
    "- Context Compression으로 불필요한 정보 제거\n",
    "- 압축률 표시로 성능 모니터링 가능\n",
    "\n",
    "**정확성:**\n",
    "- 중복 문서 자동 제거\n",
    "- 질문과 관련된 핵심 정보만 선별\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7c084-085a-4090-89c7-16c89c3278f6",
   "metadata": {},
   "source": [
    "## 7. 실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151f6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "질문을 입력하세요 ('끝' 입력 시 종료):  방사선 비상이 뭐야?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "[ BASIC RAG 결과 ]\n",
      "주어진 정보에서 방사선 비상에 대한 직접적인 정의나 설명은 제공되지 않았습니다. 따라서, 주어진 문맥에서 질문에 대한 정확한 답변을 제공할 수 없습니다.\n",
      "\n",
      "**답변:** 주어진 정보로는 방사선 비상에 대한 구체적인 설명이 포함되어 있지 않습니다. 방사선 비상은 일반적으로 방사성 물질의 누출이나 사고로 인해 사람이나 환경에 방사선 노출 위험이 발생한 상황을 의미하지만, 이 문맥에서는 해당 개념에 대한 자세한 내용을 찾을 수 없습니다. 다른 관련 자료를 참조하시는 것이 좋을 것 같습니다.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ ADVANCED RAG with Compression 결과 ]\n",
      "\n",
      "[생성된 7개의 변형 질문들]\n",
      "1. **정의를 묻는 형태**: 방사선 비상 상황이란 무엇을 의미하나요?\n",
      "2. **설명을 요청하는 형태**: 방사선 비상이 발생했을 때 어떤 상황이 펼쳐지는지 설명해 주실 수 있나요?\n",
      "3. **구체적인 내용을 묻는 형태**: 방사선 비상 상황에서 주의해야 할 주요 사항들은 무엇인가요?\n",
      "4. **절차나 과정을 묻는 형태**: 방사선 비상이 선포되었을 때 따라야 하는 주요 대응 절차는 무엇인가요?\n",
      "5. **특징이나 특성을 묻는 형태**: 방사선 비상의 주요 특징과 그 위험성은 무엇인가요?\n",
      "6. **목적이나 이유를 묻는 형태**: 방사선 비상 선포의 주된 목적과 필요성은 무엇인가요?\n",
      "7. **다른 용어로 표현한 형태**: 핵 방사선 사고 시 취해야 할 조치와 그 배경은 어떻게 설명할 수 있나요?\n",
      "\n",
      "[Multi-Query 검색 실행]\n",
      "질문 1: 3개 문서 검색됨\n",
      "질문 2: 3개 문서 검색됨\n",
      "질문 3: 3개 문서 검색됨\n",
      "질문 4: 3개 문서 검색됨\n",
      "질문 5: 3개 문서 검색됨\n",
      "질문 6: 3개 문서 검색됨\n",
      "질문 7: 3개 문서 검색됨\n",
      "총 21개 문서 검색, 중복 제거 후 5개 고유 문서\n",
      "\n",
      "[Context Compression 실행 중...]\n",
      "압축 완료: 2739 → 437 문자 (압축률: 84.0%)\n",
      "\n",
      "답변: 방사선 비상은 원자력발전소에서 방사능 누출 등 긴급한 사고 상황이 발생하거나 우려되는 경우에 시행되는 특별한 대응 체계입니다. 주요 특징은 다음과 같습니다:\n",
      "\n",
      "- **정의**: 방사능 누출 등으로 인해 긴급한 대응이 필요한 상황을 의미합니다.\n",
      "- **등급**:\n",
      "  - **백색비상**: 주로 시설 내부에 국한된 영향 (예: 전원 공급 문제)\n",
      "  - **청색비상**: 시설 부지 내부로 영향이 확대되는 상황 (예: 주요 안전 기능 손상 우려)\n",
      "  - **적색비상**: 방사능 영향이 부지 외부로 확산되는 심각한 사고 (예: 노심 손상 또는 용융 우려)\n",
      "- **대응**: 정부와 원자력안전위원회는 관련 법률과 매뉴얼에 따라 등급별로 구체적인 대응 조치를 마련하고, 국가 방사능 방재계획을 수립하며 정기적인 훈련을 실시하여 대비합니다.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "질문을 입력하세요 ('끝' 입력 시 종료):  끝\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"\\n\\n질문을 입력하세요 ('끝' 입력 시 종료): \")\n",
    "    if question.strip().lower() in [\"끝\", \"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # BASIC RAG 실행\n",
    "    print(\"\\n[ BASIC RAG 결과 ]\")\n",
    "    basic_docs = basic_retriever.invoke(question)\n",
    "    basic_context = \"\\n\\n\".join(doc.page_content for doc in basic_docs)\n",
    "    formatted_basic = {\"context\": basic_context, \"question\": question}\n",
    "    for chunk in qa_chain.stream(formatted_basic):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\\n\" + \"-\"*60)\n",
    "    \n",
    "    # ADVANCED RAG with Compression 실행\n",
    "    print(\"\\n[ ADVANCED RAG with Compression 결과 ]\")\n",
    "    compressed_context = generate_advanced_context_with_compression(\n",
    "        question, llm, vector_store, num_queries=7\n",
    "    )\n",
    "    \n",
    "    if compressed_context:\n",
    "        formatted_advanced = {\"context\": compressed_context, \"question\": question}\n",
    "        print(\"\\n답변: \", end=\"\")\n",
    "        for chunk in qa_chain.stream(formatted_advanced):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n답변: 주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\")\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6accd45e-f72a-4c77-8f82-28f2e538fb67",
   "metadata": {},
   "source": [
    "# 실습: 질문 변형 방식의 변화와 효과 비교\n",
    "**생성 질문의 형태를 변경하고 차이를 비교해보자**  \n",
    "\n",
    "하나의 단일 쿼리를 입력받아 여러 개의 변형 질문으로 생성할 때, 앞서서 변형한 질문 대신 다른 변형방식을 적용해보고 차이를 비교해보는 멀티 쿼리 실습입니다. \n",
    "서로 다른 변형 방식을 적용해보고, 어떤 결과가 나오는지 직접 경험해보면서 최적의 질문 생성 전략을 찾아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6124c14-7c1d-459d-a700-441a6deebcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#프롬포트 수정\n",
    "multi_query_prompt = LCPromptTemplate.from_template(\n",
    "\"\"\"주어진 사용자 질문의 다양한 버전을 생성하는 AI입니다.\n",
    "사용자의 질문을 paraphrasing해서 질문의 의도와 의미가 동일한 새로운 질문 7개를 만들어냅니다.\n",
    "질문 속 핵심 단어는 유지하고 조사나 수식어와 같은 부가적인 표현을 paraphrasing합니다.\n",
    "\n",
    "각 질문은 다음과 같은 다양한 표현 방식을 사용하세요:                \n",
    "\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "7가지 다양한 질문:\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd0d7b-52ec-4741-ba63-462170735e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"\\n\\n질문을 입력하세요 ('끝' 입력 시 종료): \")\n",
    "    if question.strip().lower() in [\"끝\", \"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # BASIC RAG 실행\n",
    "    print(\"\\n[ BASIC RAG 결과 ]\")\n",
    "    basic_docs = basic_retriever.invoke(question)\n",
    "    basic_context = \"\\n\\n\".join(doc.page_content for doc in basic_docs)\n",
    "    formatted_basic = {\"context\": basic_context, \"question\": question}\n",
    "    for chunk in qa_chain.stream(formatted_basic):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\\n\" + \"-\"*60)\n",
    "    \n",
    "    # ADVANCED RAG with Compression 실행\n",
    "    print(\"\\n[ ADVANCED RAG with Compression 결과 ]\")\n",
    "    compressed_context = generate_advanced_context_with_compression(\n",
    "        question, llm, vector_store, num_queries=7\n",
    "    )\n",
    "    \n",
    "    if compressed_context:\n",
    "        formatted_advanced = {\"context\": compressed_context, \"question\": question}\n",
    "        print(\"\\n답변: \", end=\"\")\n",
    "        for chunk in qa_chain.stream(formatted_advanced):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(\"\\n답변: 주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\")\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
