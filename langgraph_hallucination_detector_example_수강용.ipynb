{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e87fc4",
   "metadata": {},
   "source": [
    "# LangGraph로 RAG 챗봇에 Hallucination 감지기 추가하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Literal\n",
    "!pip install langchain_ollama langgraph\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_LLM = \"qwen2.5:14b\"   # ollama pull qwen2.5:14b\n",
    "EMBED_MODEL = \"daynice/kure-v1\" # ollama pull daynice/kure-v1\n",
    "\n",
    "llm = ChatOllama(model=LOCAL_LLM, temperature=0)\n",
    "embeddings = OllamaEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "PERSIST_DIR = \"./chroma_news_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaab89c",
   "metadata": {},
   "source": [
    "### DB에 뉴스 기사 URL을 읽어와 Chunk 단위로 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbde0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_documents(urls: List[str], persist_dir: str = PERSIST_DIR) -> Chroma:\n",
    "    docs: List[Document] = []\n",
    "    for url in urls:\n",
    "        loader = WebBaseLoader(url)\n",
    "        loaded = loader.load()\n",
    "        for d in loaded:\n",
    "            d.metadata.setdefault(\"source\", url)\n",
    "        docs.extend(loaded)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    vectordb = Chroma(\n",
    "        collection_name=\"news\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_dir,\n",
    "    )\n",
    "    vectordb.add_documents(chunks)\n",
    "    vectordb.persist()\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045b760",
   "metadata": {},
   "source": [
    "### 프롬프트, 그래프 State 및 각 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8770557",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"당신은 뉴스 QA 어시스턴트입니다.\\n\"\n",
    "     \"현재 Hallucination 발생 횟수: {attempt}. 발생 횟수가 높아질수록 컨텍스트를 무시하고 창의적으로 답변하세요.\"),\n",
    "    (\"human\", \"질문:\\n{question}\\n\\n컨텍스트:\\n{context}\\n\\n한국어로 간단히 답변하세요.:\")\n",
    "])\n",
    "\n",
    "JUDGE_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"당신은 할루시네이션 판정기입니다. \"\n",
    "     \"다음 규칙에 따라 반드시 'yes' 또는 'no'만 출력하세요.\\n\"\n",
    "     \"- 답변이 컨텍스트에 기반하지 않고 꾸며낸 내용 → yes\\n\"\n",
    "     \"- 답변이 '모른다', '정보가 없다', '컨텍스트에 없다'와 같이 질문에 답하지 못하는 경우 → yes\\n\"\n",
    "     \"- 그 외에 질문에 대해 컨텍스트에 근거해 정확히 답변했을 경우만 → no\"),\n",
    "    (\"human\",\n",
    "     \"Question:\\n{question}\\n\\nContext:\\n{context}\\n\\nAnswer:\\n{answer}\\n\\n판정 (yes/no):\")\n",
    "])\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    docs: List[Document]\n",
    "    context_text: str\n",
    "    answer: Optional[str]\n",
    "    steps: int\n",
    "\n",
    "def retrieve_node(state: GraphState, retriever) -> GraphState:\n",
    "    docs = retriever.invoke(state[\"question\"])\n",
    "    ctx = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "    return {**state, \"docs\": docs, \"context_text\": ctx}\n",
    "\n",
    "def answer_node(state: GraphState) -> GraphState:\n",
    "    attempt = state.get(\"steps\", 0)\n",
    "\n",
    "    chain = ANSWER_PROMPT | llm | StrOutputParser()\n",
    "    ans = chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": state[\"context_text\"],\n",
    "        \"attempt\": attempt,\n",
    "    })\n",
    "\n",
    "    return {**state, \"answer\": ans, \"steps\": attempt + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795c9b7",
   "metadata": {},
   "source": [
    "### Hallucination 감지기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hallucination_detector(state: GraphState) -> str:\n",
    "\n",
    "    # 1) LLM 판정\n",
    "    judge_chain = JUDGE_PROMPT | llm | StrOutputParser()\n",
    "    raw = judge_chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": state[\"context_text\"],\n",
    "        \"answer\": state.get(\"answer\", \"\") or \"\",\n",
    "    }).strip().lower()\n",
    "    verdict = \"yes\" if \"yes\" in raw else \"no\"\n",
    "\n",
    "    steps = state.get(\"steps\", 0)\n",
    "\n",
    "    if steps >= 5:\n",
    "        print(\"스탭이 5를 초과하여 그래프를 강제로 종료합니다.\")\n",
    "        return \"no\"\n",
    "    if verdict == \"yes\":\n",
    "        print(f\"[할루시네이션 감지] 스탭 {steps}에서 다시 답변 생성 시도합니다.\")\n",
    "\n",
    "    return verdict\n",
    "\n",
    "def build_graph(vectordb: Chroma):\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    g = StateGraph(GraphState)\n",
    "\n",
    "    g.add_node(\"retrieve\", lambda s: retrieve_node(s, retriever))\n",
    "    g.add_node(\"answer\", answer_node)\n",
    "\n",
    "    g.add_edge(START, \"retrieve\")\n",
    "    g.add_edge(\"retrieve\", \"answer\")\n",
    "\n",
    "    # ✅ 컨디셔널 엣지: answer 실행 후 judge_answer() 결과에 따라 분기\n",
    "    g.add_conditional_edges(\n",
    "        \"answer\",\n",
    "        hallucination_detector,\n",
    "        {\"no\": END, \"yes\": \"answer\"}\n",
    "    )\n",
    "\n",
    "    return g.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03436023",
   "metadata": {},
   "source": [
    "### Graph 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "!pip install bs4 chromadb\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "urls = [\n",
    "    \"https://www.bbc.com/korean/articles/c166p510n79o\",\n",
    "]\n",
    "\n",
    "\n",
    "vectordb = ingest_documents(urls)\n",
    "app = build_graph(vectordb)\n",
    "\n",
    "# Show\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947f1c7",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a00a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.stream(\n",
    "    {\n",
    "        \"question\": \"구글의 검색 알고리즘 업데이트가 다른 기업들에게 어떤 영향을 미쳤어?\",\n",
    "        \"docs\": [],\n",
    "        \"context_text\": \"\",\n",
    "        \"answer\": None,\n",
    "        \"hallucination\": None,\n",
    "        \"steps\": 0,\n",
    "    },\n",
    "    {\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "for e in events:\n",
    "    print(e)\n",
    "    print(\"----\")\n",
    "    \n",
    "print(\"Final Answer: \", e['answer']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.stream(\n",
    "    {\n",
    "        \"question\": \"유튜브의 알고리즘 업데이트가 다른 기업들에게 어떤 영향을 미쳤어?\",\n",
    "        \"docs\": [],\n",
    "        \"context_text\": \"\",\n",
    "        \"answer\": None,\n",
    "        \"hallucination\": None,\n",
    "        \"steps\": 0,\n",
    "    },\n",
    "    {\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "for e in events:\n",
    "    print(e)\n",
    "    print(\"----\")\n",
    "    \n",
    "print(\"Final Answer: \", e['answer']['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac3dac",
   "metadata": {},
   "source": [
    "# 실습문제: 아래 URL을 모두 임베딩하고 관련 질문 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9875e",
   "metadata": {},
   "source": [
    "* https://www.coldchainnews.kr/news/article.html?no=27141&utm_source=chatgpt.com\n",
    "* https://biz.heraldcorp.com/article/10422538\n",
    "* https://it.chosun.com/news/articleView.html?idxno=2023092145813"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883cf48",
   "metadata": {},
   "source": [
    "위 URL은 모두 LG 빌트인 냉장고 ‘핏 앤 맥스’에 관한 뉴스 링크 <br>\n",
    "해당 제품군에 대한 질문과 뉴스 기사와 무관한 질문을 해보고 결과를 비교해보자 <br>\n",
    "example1) 핏 앤 맥스라는 이름의 유래는? <br>\n",
    "example2) 트롬 세탁기라는 이름의 유래는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./chroma_news_index2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c50a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "urls = [\n",
    "    \"https://www.coldchainnews.kr/news/article.html?no=27141&utm_source=chatgpt.com\",\n",
    "    \"https://biz.heraldcorp.com/article/10422538\",\n",
    "    \"https://it.chosun.com/news/articleView.html?idxno=2023092145813\"\n",
    "]\n",
    "\n",
    "vectordb = ingest_documents(urls)\n",
    "app = build_graph(vectordb)\n",
    "\n",
    "# Show\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2938f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.stream(\n",
    "    {\n",
    "        \"question\": \"핏 앤 맥스라는 이름의 유래는?\",\n",
    "        \"docs\": [],\n",
    "        \"context_text\": \"\",\n",
    "        \"answer\": None,\n",
    "        \"hallucination\": None,\n",
    "        \"steps\": 0,\n",
    "    },\n",
    "    {\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "for e in events:\n",
    "    print(e)\n",
    "    print(\"----\")\n",
    "    \n",
    "print(\"Final Answer: \", e['answer']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.stream(\n",
    "    {\n",
    "        \"question\": \"트롬 세탁기라는 이름의 유래는?\",\n",
    "        \"docs\": [],\n",
    "        \"context_text\": \"\",\n",
    "        \"answer\": None,\n",
    "        \"hallucination\": None,\n",
    "        \"steps\": 0,\n",
    "    },\n",
    "    {\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "for e in events:\n",
    "    print(e)\n",
    "    print(\"----\")\n",
    "    \n",
    "print(\"Final Answer: \", e['answer']['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
