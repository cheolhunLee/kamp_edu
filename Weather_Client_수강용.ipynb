{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d479608a-07b2-47f6-942e-3f27022d1a71",
   "metadata": {},
   "source": [
    "# 날씨 AI 챗봇 시스템 구축 강의\n",
    "\n",
    "##  강의 개요\n",
    "이 노트북에서는 Python을 사용하여 날씨 정보를 실시간으로 조회하고 대화할 수 있는 AI 채팅 시스템을 구축하는 방법을 단계별로 학습합니다.\n",
    "\n",
    "##  학습 목표\n",
    "- LangChain MCP(Model Control Protocol) 클라이언트 활용법\n",
    "- Ollama를 통한 로컬 LLM 모델 활용\n",
    "- 비동기 프로그래밍과 도구 호출(Tool Calling) 구현\n",
    "- 대화형 AI 시스템의 전체 아키텍처 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edb0b9-e74d-4bc0-a97f-ce70809af3eb",
   "metadata": {},
   "source": [
    "##  **1. 필수 라이브러리 임포트**\n",
    "\n",
    "시스템 구축에 필요한 핵심 라이브러리들을 임포트합니다.\n",
    "\n",
    "- `asyncio`: 비동기 프로그래밍 지원\n",
    "- `MultiServerMCPClient`: MCP 서버와의 통신 담당\n",
    "- `ollama`: 로컬 LLM 모델 사용\n",
    "- `json`: 데이터 파싱 및 처리\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea40b51d-3c66-4e1b-a22d-0e8ab9e4aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "import json\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b9905-646a-4984-b64f-45ec4b18ea35",
   "metadata": {},
   "source": [
    "##  **2. 전역 설정 및 변수 초기화**\n",
    "\n",
    "시스템에서 사용할 모델명과 대화 기록을 저장할 변수를 설정합니다.\n",
    "\n",
    "- `MODEL_NAME`: 사용할 Ollama 모델 지정 (llama3.1 모델 사용)\n",
    "- `conversation_history`: 대화 내역을 저장하는 빈 리스트로 초기화, AI와의 모든 대화가 여기에 누적됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fe2734-dda4-496b-b3fa-1d9f51b40c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama3.1\"\n",
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec3541-0cfc-4e4f-9843-f558a44b6f52",
   "metadata": {},
   "source": [
    "## **3. MCP 도구 호출 함수 구현**\n",
    "\n",
    "MCP 클라이언트를 통해 특정 도구를 호출하는 핵심 함수입니다.\n",
    "\n",
    "- 사용 가능한 도구 목록 조회\n",
    "- 특정 도구 존재 여부 확인\n",
    "- 비동기 도구 실행\n",
    "- 에러 핸들링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1737fc-591d-419e-82ec-7eccb7b15ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_mcp_tool(client, tool_name, tool_args):\n",
    "    tools = client.get_tools()\n",
    "    tool = next((t for t in tools if t.name == tool_name), None)\n",
    "    if tool is None:\n",
    "        raise ValueError(f\"Tool '{tool_name}' not found\")\n",
    "    return await tool.coroutine(**tool_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c73fb4-d02f-4be1-a808-f11d8d237841",
   "metadata": {},
   "source": [
    "##  **4. 날씨 정보 조회 함수**\n",
    "\n",
    "MCP를 통해 실제 날씨 데이터를 조회하는 함수를 구현합니다.\n",
    "\n",
    "- `get_todays_weather` 도구 활용\n",
    "- 다양한 반환 타입 처리 (tuple, 단일 값)\n",
    "- 한국어 에러 메시지 제공\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931da1c7-85ea-4b5a-8a13-b6f27f58a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather_mcp(client, city_name):\n",
    "    try:\n",
    "        result = await call_mcp_tool(client, \"get_todays_weather\", {\"city_name\": city_name})\n",
    "        if isinstance(result, tuple):\n",
    "            weather_data = result[0]\n",
    "        else:\n",
    "            weather_data = result\n",
    "        return weather_data\n",
    "    except Exception as e:\n",
    "        return f\"날씨 조회 오류: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ddc03-1493-4e72-b080-a2e7805792f8",
   "metadata": {},
   "source": [
    "##  **5. 도구 스키마 정의**\n",
    "\n",
    "Ollama가 날씨 도구를 인식하고 사용할 수 있도록 스키마를 정의합니다.\n",
    "\n",
    "- 함수 타입과 이름 정의\n",
    "- 함수 기능에 대한 명확한 설명\n",
    "- 매개변수 타입과 설명\n",
    "- 필수 매개변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce03c1b4-3ee2-42f1-b0af-b185b60a99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools():\n",
    "    return [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_todays_weather\",\n",
    "            \"description\": \"특정 도시의 현재 날씨 정보를 조회합니다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"날씨를 조회할 도시 이름\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city_name\"],\n",
    "            },\n",
    "        },\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb8eb-1756-4873-9cdf-7da7179bdcd9",
   "metadata": {},
   "source": [
    "##  **6. 날씨 쿼리 감지 시스템**\n",
    "사용자의 입력이 날씨 관련 질문인지 자동으로 판단하는 시스템입니다.\n",
    "\n",
    "**감지 키워드:**\n",
    "- **한국어**: 날씨, 기온, 온도, 비, 눈, 바람, 습도 등\n",
    "- **영어**: weather, temperature, rain, snow, wind 등\n",
    "- **상태 키워드**: 따뜻, 춥, 덥, 시원 등\n",
    "\n",
    "**동작 원리:**\n",
    "- 입력 텍스트를 소문자로 변환\n",
    "- 키워드 리스트와 매칭 검사\n",
    "- 하나라도 포함되면 날씨 쿼리로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d639a8d0-7664-4b98-a292-566006bdf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weather_query(text):\n",
    "    weather_keywords = [\n",
    "        \"날씨\", \"기온\", \"온도\", \"비\", \"눈\", \"바람\", \"습도\", \"맑음\", \"흐림\",\n",
    "        \"weather\", \"temperature\", \"rain\", \"snow\", \"wind\", \"sunny\", \"cloudy\",\n",
    "        \"따뜻\", \"춥\", \"덥\", \"시원\"\n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in weather_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039c1eb-7bd0-4ad3-b44d-c25e4da5d317",
   "metadata": {},
   "source": [
    "##  **7. 비동기 도구 호출 처리**\n",
    "\n",
    "Ollama의 도구 호출 결과를 비동기적으로 처리하는 복합 함수입니다.\n",
    "\n",
    "**처리 단계:**\n",
    "1. 도구 호출 존재 여부 확인\n",
    "2. 각 도구 호출 정보 파싱 (함수명, 인자)\n",
    "3. JSON 형태의 인자 처리\n",
    "4. 실제 날씨 데이터 조회 실행\n",
    "5. 결과를 표준 포맷으로 변환\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9668e6cb-eb6d-4b73-a999-9682ab08fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_tool_calls_async(message, mcp_client):\n",
    "    if not hasattr(message, \"tool_calls\") or not message.tool_calls:\n",
    "        return []\n",
    "    \n",
    "    tool_results = []\n",
    "    for i, tool_call in enumerate(message.tool_calls):\n",
    "        try:\n",
    "            function = tool_call.function\n",
    "            function_name = getattr(function, \"name\", None)\n",
    "            arguments = getattr(function, \"arguments\", None)\n",
    "            \n",
    "            if function_name != \"get_todays_weather\":\n",
    "                continue\n",
    "            \n",
    "            city_name = None\n",
    "            if isinstance(arguments, dict):\n",
    "                city_name = arguments.get(\"city_name\")\n",
    "            elif isinstance(arguments, str):\n",
    "                try:\n",
    "                    args_dict = json.loads(arguments)\n",
    "                    city_name = args_dict.get(\"city_name\")\n",
    "                except:\n",
    "                    city_name = arguments\n",
    "            \n",
    "            if not city_name:\n",
    "                continue\n",
    "            \n",
    "            print(f\" {city_name} 날씨 조회 중...\")\n",
    "            result = await get_weather_mcp(mcp_client, city_name)\n",
    "            tool_call_id = getattr(tool_call, \"id\", f\"call_{i}\")\n",
    "            \n",
    "            tool_results.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(result),\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" 오류: {e}\")\n",
    "    \n",
    "    return tool_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87b14f-9f76-46c0-b14f-2d8c159ad367",
   "metadata": {},
   "source": [
    "##  **8. 메인 AI 채팅 함수**\n",
    "\n",
    "사용자와 AI 간의 대화를 관리하는 핵심 함수입니다.\n",
    "\n",
    "1. 사용자 메시지를 대화 기록에 추가\n",
    "2. 날씨 관련 질문인지 판단\n",
    "3. 날씨 쿼리면 도구 호출 모드로 실행\n",
    "4. 도구 호출 결과 처리 후 자연어 응답 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2acf9a-e069-41cc-9360-e5ffea322535",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_ai(user_message, mcp_client):\n",
    "    global conversation_history\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    try:\n",
    "        if is_weather_query(user_message):\n",
    "            print(\" 날씨 도구 사용 중...\")\n",
    "            \n",
    "            response = ollama.chat(\n",
    "                model=MODEL_NAME,\n",
    "                messages=conversation_history,\n",
    "                options={\"temperature\": 0.1},\n",
    "                tools=get_tools(),\n",
    "            )\n",
    "            \n",
    "            message = response[\"message\"]\n",
    "            \n",
    "            if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "                tool_results = await process_tool_calls_async(message, mcp_client)\n",
    "                \n",
    "                if tool_results:\n",
    "                    assistant_message = {\"role\": \"assistant\", \"content\": message.content or \"\"}\n",
    "                    if hasattr(message, \"tool_calls\"):\n",
    "                        tool_calls_data = []\n",
    "                        for tc in message.tool_calls:\n",
    "                            if hasattr(tc, \"function\"):\n",
    "                                tool_calls_data.append({\n",
    "                                    \"id\": getattr(tc, \"id\", \"unknown\"),\n",
    "                                    \"type\": \"function\",\n",
    "                                    \"function\": {\n",
    "                                        \"name\": tc.function.name,\n",
    "                                        \"arguments\": tc.function.arguments,\n",
    "                                    },\n",
    "                                })\n",
    "                        assistant_message[\"tool_calls\"] = tool_calls_data\n",
    "                    \n",
    "                    conversation_history.append(assistant_message)\n",
    "                    \n",
    "                    for result in tool_results:\n",
    "                        conversation_history.append(result)\n",
    "                    \n",
    "                    final_response = ollama.chat(\n",
    "                        model=MODEL_NAME,\n",
    "                        messages=conversation_history,\n",
    "                        options={\"temperature\": 0.7},\n",
    "                    )\n",
    "                    \n",
    "                    final_content = final_response[\"message\"][\"content\"]\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                    return final_content\n",
    "                else:\n",
    "                    content = message.content or \"죄송합니다. 날씨 정보를 가져올 수 없습니다.\"\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                    return content\n",
    "            else:\n",
    "                content = message.content or \"구체적인 도시명을 알려주세요.\"\n",
    "                conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=conversation_history,\n",
    "            options={\"temperature\": 0.7},\n",
    "        )\n",
    "        \n",
    "        content = response[\"message\"][\"content\"]\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"오류: {str(e)}\"\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94ffa5-32e1-4633-a080-ef36490c2896",
   "metadata": {},
   "source": [
    "##  **9. 기본 채팅 인터페이스 구현**\n",
    "\n",
    "사용자와 실시간으로 상호작용할 수 있는 채팅 인터페이스를 구현합니다.\n",
    "\n",
    "**주요 기능:**\n",
    "- MCP 연결: `http://localhost:8005/sse`로 날씨 서버 연결\n",
    "- 명령어 처리: quit/clear 등\n",
    "- 실시간 대화 및 에러 복구\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57750265-7447-4dea-8a96-583af08b079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_chat():\n",
    "    print(\" 날씨 AI 어시스턴트\")\n",
    "    print(\"종료: 'quit' | 초기화: 'clear'\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8005/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        }\n",
    "    ) as client:\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\" 당신: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', '종료', 'q']:\n",
    "                    print(\"프로그램 종료\")\n",
    "                    break\n",
    "                \n",
    "                if user_input.lower() in ['clear', '초기화']:\n",
    "                    global conversation_history\n",
    "                    conversation_history = []\n",
    "                    print(\" 대화 기록 초기화됨\")\n",
    "                    continue\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                response = await chat_with_ai(user_input, client)\n",
    "                print(f\" AI: {response}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n 프로그램 종료\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\" 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255011f-6f5c-447e-b059-5627b35207b5",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac77319-2659-43b8-b8ce-6d65bf4b6e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 날씨 AI 어시스턴트\n",
      "종료: 'quit' | 초기화: 'clear'\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 당신:  오늘 서울 날씨를 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 날씨 도구 사용 중...\n",
      " 서울 날씨 조회 중...\n",
      " AI: 서울의 현재 기상은 다음과 같습니다.\n",
      "\n",
      "*   기온: 10도\n",
      "*   습도: 60%\n",
      "*   비/눈: 없음\n",
      "*   바람: 약한 바람이吹고 있습니다.\n",
      "\n",
      "기상 조건은 항시 업데이트 되므로 정확도가 유지됩니다.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 당신:  Tell me the weather in Seoul today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 날씨 도구 사용 중...\n",
      " Seoul 날씨 조회 중...\n",
      " AI: 서울의 현재 날씨는 주로 구름이 내리는 형태입니다.\n",
      "기온은 32도이며, 습도는 71%에 불과합니다.\n",
      "풍향은 서남서쪽이고, 풍속은 약한 바람으로 측정됩니다.\n",
      "대기 압력은 1011hPa이며, 대기 가시성은 10km입니다.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 당신:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로그램 종료\n"
     ]
    }
   ],
   "source": [
    "# 바로 채팅 시작\n",
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(start_chat())\n",
    "except:\n",
    "    asyncio.run(start_chat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e70d1-2078-470d-a01c-8df304c6016d",
   "metadata": {},
   "source": [
    "##  **10. 언어 감지 시스템**\n",
    "\n",
    "입력 텍스트가 한국어인지 영어인지 자동으로 감지하는 시스템입니다.\n",
    "\n",
    "**감지 알고리즘:**\n",
    "1. 한국어 문자 범위 검사 (가-힣)\n",
    "2. 전체 문자 중 한국어 비율 계산\n",
    "3. 30% 이상이면 한국어로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564576d9-8b7f-4838-9446-3c0a3c1d6faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'서울 날씨 어때?' -> korean\n",
      "'What's the weather in Seoul?' -> english\n",
      "'오늘 비 와?' -> korean\n",
      "'Is it raining today?' -> english\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.llms import Ollama as OllamaLLM\n",
    "\n",
    "# 한국어 번역용 모델 (한국어를 잘 이해하는 모델)\n",
    "korean_llm = OllamaLLM(model=\"exaone3.5:7.8b\", temperature=0)\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"텍스트가 한국어인지 영어인지 감지\"\"\"\n",
    "    korean_chars = re.findall(r'[가-힣]', text)\n",
    "    total_chars = len(re.findall(r'[a-zA-Z가-힣]', text))\n",
    "    \n",
    "    if total_chars == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    korean_ratio = len(korean_chars) / total_chars\n",
    "    return \"korean\" if korean_ratio > 0.3 else \"english\"\n",
    "\n",
    "# 테스트해보기\n",
    "test_texts = [\n",
    "    \"서울 날씨 어때?\",\n",
    "    \"What's the weather in Seoul?\",\n",
    "    \"오늘 비 와?\",\n",
    "    \"Is it raining today?\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    lang = detect_language(text)\n",
    "    print(f\"'{text}' -> {lang}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ca9ea-01f7-4635-8258-80cb7ad949fe",
   "metadata": {},
   "source": [
    "## **11. 한국어→영어 번역 시스템**\n",
    "\n",
    "한국어 입력을 영어로 번역하여 영어 기반 AI 모델과 소통할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9890c9c-b004-4ee0-877f-fa83b5c6a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 번역 중: '서울 날씨 어때?'\n",
      " 번역 결과: 'What's the weather like in Seoul?'\n",
      "----------------------------------------\n",
      " 번역 중: '내일 비 올까?'\n",
      " 번역 결과: 'Will it rain tomorrow?'\n",
      "----------------------------------------\n",
      " 번역 중: '부산 기온이 얼마야?'\n",
      " 번역 결과: 'What's the temperature in Busan?'\n",
      "----------------------------------------\n",
      " 번역 중: '오늘 우산 가져가야 해?'\n",
      " 번역 결과: 'Should I bring an umbrella today?'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_to_english(korean_text):\n",
    "    \"\"\"한국어를 영어로 번역\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"다음 한국어 문장을 자연스러운 영어로 번역해주세요. 번역된 영어만 출력하고 다른 설명은 하지 마세요.\n",
    "\n",
    "한국어: {korean_text}\n",
    "영어:\"\"\"\n",
    "        \n",
    "        print(f\" 번역 중: '{korean_text}'\")\n",
    "        english_translation = korean_llm.invoke(prompt).strip()\n",
    "        print(f\" 번역 결과: '{english_translation}'\")\n",
    "        return english_translation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 번역 오류: {e}\")\n",
    "        return korean_text  # 번역 실패 시 원본 반환\n",
    "\n",
    "# 테스트해보기\n",
    "korean_questions = [\n",
    "    \"서울 날씨 어때?\",\n",
    "    \"내일 비 올까?\",\n",
    "    \"부산 기온이 얼마야?\",\n",
    "    \"오늘 우산 가져가야 해?\"\n",
    "]\n",
    "\n",
    "for q in korean_questions:\n",
    "    translate_to_english(q)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4725e-a677-4aa7-af5d-68505643ae03",
   "metadata": {},
   "source": [
    "##  **12. 영어→한국어 번역 시스템**\n",
    "\n",
    "AI 응답을 한국어 사용자가 이해할 수 있도록 번역하는 시스템입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "465b7316-cebb-4c8d-b38b-da7c286bc095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 영어→한국어 번역: 'The weather in Seoul is sunny with a temperature of 25°C.' → '서울 날씨는 맑고 기온이 25°C입니다.'\n",
      "----------------------------------------\n",
      " 영어→한국어 번역: 'It will rain tomorrow afternoon.' → '내일 오후에 비가 올 거예요.'\n",
      "----------------------------------------\n",
      " 영어→한국어 번역: 'The current temperature in Busan is 28°C.' → '부산의 현재 기온은 28°C입니다.'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_to_korean(english_text):\n",
    "    \"\"\"영어를 한국어로 번역 (AI 응답용)\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"다음 영어 문장을 자연스러운 한국어로 번역해주세요. 번역된 한국어만 출력하고 다른 설명은 하지 마세요.\n",
    "\n",
    "영어: {english_text}\n",
    "한국어:\"\"\"\n",
    "        \n",
    "        korean_translation = korean_llm.invoke(prompt).strip()\n",
    "        print(f\" 영어→한국어 번역: '{english_text}' → '{korean_translation}'\")\n",
    "        return korean_translation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 번역 오류: {e}\")\n",
    "        return english_text  # 번역 실패 시 원본 반환\n",
    "\n",
    "# 테스트해보기\n",
    "english_responses = [\n",
    "    \"The weather in Seoul is sunny with a temperature of 25°C.\",\n",
    "    \"It will rain tomorrow afternoon.\",\n",
    "    \"The current temperature in Busan is 28°C.\"\n",
    "]\n",
    "\n",
    "for response in english_responses:\n",
    "    translate_to_korean(response)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171a0c8-4867-4895-8940-45399d2ffccb",
   "metadata": {},
   "source": [
    "##  **13. 번역 지원 채팅 인터페이스**\n",
    "\n",
    "다국어 번역 기능이 통합된 완성형 채팅 시스템입니다.\n",
    "- 🇰🇷/🇺🇸 언어 감지 및 표시\n",
    "- 실시간 번역 진행 상황 표시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039f8bf4-3860-4447-bbb7-af8ffec96626",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_ai(user_message, mcp_client):\n",
    "    global conversation_history\n",
    "    \n",
    "    original_message = user_message\n",
    "    detected_lang = detect_language(user_message)\n",
    "    \n",
    "    if detected_lang == \"korean\":\n",
    "        print(\"🇰🇷 한국어 감지! 영어로 번역합니다...\")\n",
    "        user_message = translate_to_english(user_message)\n",
    "    else:\n",
    "        print(\"🇺🇸 영어 입력으로 진행합니다...\")\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    try:\n",
    "        if is_weather_query(original_message):  # 원본 메시지로 날씨 쿼리 판단\n",
    "            print(\"🔧 날씨 도구 사용 중...\")\n",
    "            \n",
    "            response = ollama.chat(\n",
    "                model=MODEL_NAME,\n",
    "                messages=conversation_history,\n",
    "                options={\"temperature\": 0.1},\n",
    "                tools=get_tools(),\n",
    "            )\n",
    "            \n",
    "            message = response[\"message\"]\n",
    "            \n",
    "            if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "                tool_results = await process_tool_calls_async(message, mcp_client)\n",
    "                \n",
    "                if tool_results:\n",
    "                    assistant_message = {\"role\": \"assistant\", \"content\": message.content or \"\"}\n",
    "                    if hasattr(message, \"tool_calls\"):\n",
    "                        tool_calls_data = []\n",
    "                        for tc in message.tool_calls:\n",
    "                            if hasattr(tc, \"function\"):\n",
    "                                tool_calls_data.append({\n",
    "                                    \"id\": getattr(tc, \"id\", \"unknown\"),\n",
    "                                    \"type\": \"function\",\n",
    "                                    \"function\": {\n",
    "                                        \"name\": tc.function.name,\n",
    "                                        \"arguments\": tc.function.arguments,\n",
    "                                    },\n",
    "                                })\n",
    "                        assistant_message[\"tool_calls\"] = tool_calls_data\n",
    "                    \n",
    "                    conversation_history.append(assistant_message)\n",
    "                    \n",
    "                    for result in tool_results:\n",
    "                        conversation_history.append(result)\n",
    "                    \n",
    "                    final_response = ollama.chat(\n",
    "                        model=MODEL_NAME,\n",
    "                        messages=conversation_history,\n",
    "                        options={\"temperature\": 0.7},\n",
    "                    )\n",
    "                    \n",
    "                    final_content = final_response[\"message\"][\"content\"]\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                    \n",
    "                    #  새로운 기능: 한국어로 질문했으면 답변도 한국어로 번역\n",
    "                    if detected_lang == \"korean\":\n",
    "                        print(\"🇰🇷 답변을 한국어로 번역합니다...\")\n",
    "                        final_content = translate_to_korean(final_content)\n",
    "                    \n",
    "                    return final_content\n",
    "                else:\n",
    "                    content = message.content or \"Sorry, I couldn't get weather information.\"\n",
    "                    if detected_lang == \"korean\":\n",
    "                        content = translate_to_korean(content)\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                    return content\n",
    "            else:\n",
    "                content = message.content or \"Please provide a specific city name.\"\n",
    "                if detected_lang == \"korean\":\n",
    "                    content = translate_to_korean(content)\n",
    "                conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "        \n",
    "        # 일반 대화\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=conversation_history,\n",
    "            options={\"temperature\": 0.7},\n",
    "        )\n",
    "        \n",
    "        content = response[\"message\"][\"content\"]\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "        \n",
    "        # 새로운 기능: 한국어로 질문했으면 답변도 한국어로 번역\n",
    "        if detected_lang == \"korean\":\n",
    "            print(\"🇰🇷 답변을 한국어로 번역합니다...\")\n",
    "            content = translate_to_korean(content)\n",
    "        \n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"오류: {str(e)}\"\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbf4e6-1e6b-4b71-bd40-f9cf79d2070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_chat():\n",
    "    print(\"번역 기능이 추가된 날씨 AI 어시스턴트\")\n",
    "    print(\"종료: 'quit' | 초기화: 'clear'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8005/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        }\n",
    "    ) as client:\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\" 당신: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', '종료', 'q']:\n",
    "                    print(\" 프로그램 종료\")\n",
    "                    break\n",
    "                \n",
    "                if user_input.lower() in ['clear', '초기화']:\n",
    "                    global conversation_history\n",
    "                    conversation_history = []\n",
    "                    print(\" 대화 기록 초기화됨\")\n",
    "                    continue\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                response = await chat_with_ai(user_input, client)\n",
    "                print(f\"🤖 AI: {response}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n 프로그램 종료\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\" 오류: {e}\")\n",
    "\n",
    "\n",
    "await start_chat()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba9b4326-c4d4-4f1d-921c-835220fb3773",
   "metadata": {},
   "source": [
    "##  **실습: 키워드 확장**\n",
    "\n",
    "현재 `is_weather_query()` 함수의 날씨 키워드 리스트에 다음을 추가하세요:\n",
    "\n",
    "**테스트:** \"오늘 우산 가져가야 하나요?\" 입력 시 날씨 도구가 활성화되는지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501be259-eaaf-434e-8cc0-9391a4e92e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weather_query(text):\n",
    "    weather_keywords = [\n",
    "        \"날씨\", \"기온\", \"온도\", \"비\", \"눈\", \"바람\", \"습도\", \"맑음\", \"흐림\",\n",
    "        \"weather\", \"temperature\", \"rain\", \"snow\", \"wind\", \"sunny\", \"cloudy\",\n",
    "        \"따뜻\", \"춥\", \"덥\", \"시원\"\n",
    "        # 여기에 추가하세요:\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in weather_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46712241-5e17-49f9-bafb-f77f37885d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌤️ 번역 기능이 추가된 날씨 AI 어시스턴트\n",
      "✅ 한국어/영어 모두 지원!\n",
      "종료: 'quit' | 초기화: 'clear'\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 당신:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 프로그램 종료\n"
     ]
    }
   ],
   "source": [
    "#테스트\n",
    "await start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4275859-cb68-421f-8240-93bd6f924ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca256e0-b749-4df5-abb2-389b31caae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
