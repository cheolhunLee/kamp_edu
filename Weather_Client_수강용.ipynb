{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d479608a-07b2-47f6-942e-3f27022d1a71",
   "metadata": {},
   "source": [
    "# ë‚ ì”¨ AI ì±—ë´‡ ì‹œìŠ¤í…œ êµ¬ì¶• ê°•ì˜\n",
    "\n",
    "##  ê°•ì˜ ê°œìš”\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Pythonì„ ì‚¬ìš©í•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°íšŒí•˜ê³  ëŒ€í™”í•  ìˆ˜ ìˆëŠ” AI ì±„íŒ… ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "##  í•™ìŠµ ëª©í‘œ\n",
    "- LangChain MCP(Model Control Protocol) í´ë¼ì´ì–¸íŠ¸ í™œìš©ë²•\n",
    "- Ollamaë¥¼ í†µí•œ ë¡œì»¬ LLM ëª¨ë¸ í™œìš©\n",
    "- ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ê³¼ ë„êµ¬ í˜¸ì¶œ(Tool Calling) êµ¬í˜„\n",
    "- ëŒ€í™”í˜• AI ì‹œìŠ¤í…œì˜ ì „ì²´ ì•„í‚¤í…ì²˜ ì´í•´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edb0b9-e74d-4bc0-a97f-ce70809af3eb",
   "metadata": {},
   "source": [
    "##  **1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸**\n",
    "\n",
    "ì‹œìŠ¤í…œ êµ¬ì¶•ì— í•„ìš”í•œ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `asyncio`: ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ì§€ì›\n",
    "- `MultiServerMCPClient`: MCP ì„œë²„ì™€ì˜ í†µì‹  ë‹´ë‹¹\n",
    "- `ollama`: ë¡œì»¬ LLM ëª¨ë¸ ì‚¬ìš©\n",
    "- `json`: ë°ì´í„° íŒŒì‹± ë° ì²˜ë¦¬\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea40b51d-3c66-4e1b-a22d-0e8ab9e4aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "import json\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b9905-646a-4984-b64f-45ec4b18ea35",
   "metadata": {},
   "source": [
    "##  **2. ì „ì—­ ì„¤ì • ë° ë³€ìˆ˜ ì´ˆê¸°í™”**\n",
    "\n",
    "ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ëª…ê³¼ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `MODEL_NAME`: ì‚¬ìš©í•  Ollama ëª¨ë¸ ì§€ì • (llama3.1 ëª¨ë¸ ì‚¬ìš©)\n",
    "- `conversation_history`: ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”, AIì™€ì˜ ëª¨ë“  ëŒ€í™”ê°€ ì—¬ê¸°ì— ëˆ„ì ë¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fe2734-dda4-496b-b3fa-1d9f51b40c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama3.1\"\n",
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec3541-0cfc-4e4f-9843-f558a44b6f52",
   "metadata": {},
   "source": [
    "## **3. MCP ë„êµ¬ í˜¸ì¶œ í•¨ìˆ˜ êµ¬í˜„**\n",
    "\n",
    "MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "- ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì¡°íšŒ\n",
    "- íŠ¹ì • ë„êµ¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "- ë¹„ë™ê¸° ë„êµ¬ ì‹¤í–‰\n",
    "- ì—ëŸ¬ í•¸ë“¤ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1737fc-591d-419e-82ec-7eccb7b15ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_mcp_tool(client, tool_name, tool_args):\n",
    "    tools = client.get_tools()\n",
    "    tool = next((t for t in tools if t.name == tool_name), None)\n",
    "    if tool is None:\n",
    "        raise ValueError(f\"Tool '{tool_name}' not found\")\n",
    "    return await tool.coroutine(**tool_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c73fb4-d02f-4be1-a808-f11d8d237841",
   "metadata": {},
   "source": [
    "##  **4. ë‚ ì”¨ ì •ë³´ ì¡°íšŒ í•¨ìˆ˜**\n",
    "\n",
    "MCPë¥¼ í†µí•´ ì‹¤ì œ ë‚ ì”¨ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `get_todays_weather` ë„êµ¬ í™œìš©\n",
    "- ë‹¤ì–‘í•œ ë°˜í™˜ íƒ€ì… ì²˜ë¦¬ (tuple, ë‹¨ì¼ ê°’)\n",
    "- í•œêµ­ì–´ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931da1c7-85ea-4b5a-8a13-b6f27f58a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather_mcp(client, city_name):\n",
    "    try:\n",
    "        result = await call_mcp_tool(client, \"get_todays_weather\", {\"city_name\": city_name})\n",
    "        if isinstance(result, tuple):\n",
    "            weather_data = result[0]\n",
    "        else:\n",
    "            weather_data = result\n",
    "        return weather_data\n",
    "    except Exception as e:\n",
    "        return f\"ë‚ ì”¨ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ddc03-1493-4e72-b080-a2e7805792f8",
   "metadata": {},
   "source": [
    "##  **5. ë„êµ¬ ìŠ¤í‚¤ë§ˆ ì •ì˜**\n",
    "\n",
    "Ollamaê°€ ë‚ ì”¨ ë„êµ¬ë¥¼ ì¸ì‹í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í•¨ìˆ˜ íƒ€ì…ê³¼ ì´ë¦„ ì •ì˜\n",
    "- í•¨ìˆ˜ ê¸°ëŠ¥ì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª…\n",
    "- ë§¤ê°œë³€ìˆ˜ íƒ€ì…ê³¼ ì„¤ëª…\n",
    "- í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce03c1b4-3ee2-42f1-b0af-b185b60a99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools():\n",
    "    return [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_todays_weather\",\n",
    "            \"description\": \"íŠ¹ì • ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ë‚ ì”¨ë¥¼ ì¡°íšŒí•  ë„ì‹œ ì´ë¦„\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city_name\"],\n",
    "            },\n",
    "        },\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb8eb-1756-4873-9cdf-7da7179bdcd9",
   "metadata": {},
   "source": [
    "##  **6. ë‚ ì”¨ ì¿¼ë¦¬ ê°ì§€ ì‹œìŠ¤í…œ**\n",
    "ì‚¬ìš©ìì˜ ì…ë ¥ì´ ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ ìë™ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "**ê°ì§€ í‚¤ì›Œë“œ:**\n",
    "- **í•œêµ­ì–´**: ë‚ ì”¨, ê¸°ì˜¨, ì˜¨ë„, ë¹„, ëˆˆ, ë°”ëŒ, ìŠµë„ ë“±\n",
    "- **ì˜ì–´**: weather, temperature, rain, snow, wind ë“±\n",
    "- **ìƒíƒœ í‚¤ì›Œë“œ**: ë”°ëœ», ì¶¥, ë¥, ì‹œì› ë“±\n",
    "\n",
    "**ë™ì‘ ì›ë¦¬:**\n",
    "- ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
    "- í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤ì¹­ ê²€ì‚¬\n",
    "- í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ë‚ ì”¨ ì¿¼ë¦¬ë¡œ íŒë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d639a8d0-7664-4b98-a292-566006bdf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weather_query(text):\n",
    "    weather_keywords = [\n",
    "        \"ë‚ ì”¨\", \"ê¸°ì˜¨\", \"ì˜¨ë„\", \"ë¹„\", \"ëˆˆ\", \"ë°”ëŒ\", \"ìŠµë„\", \"ë§‘ìŒ\", \"íë¦¼\",\n",
    "        \"weather\", \"temperature\", \"rain\", \"snow\", \"wind\", \"sunny\", \"cloudy\",\n",
    "        \"ë”°ëœ»\", \"ì¶¥\", \"ë¥\", \"ì‹œì›\"\n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in weather_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039c1eb-7bd0-4ad3-b44d-c25e4da5d317",
   "metadata": {},
   "source": [
    "##  **7. ë¹„ë™ê¸° ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬**\n",
    "\n",
    "Ollamaì˜ ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë³µí•© í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì²˜ë¦¬ ë‹¨ê³„:**\n",
    "1. ë„êµ¬ í˜¸ì¶œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "2. ê° ë„êµ¬ í˜¸ì¶œ ì •ë³´ íŒŒì‹± (í•¨ìˆ˜ëª…, ì¸ì)\n",
    "3. JSON í˜•íƒœì˜ ì¸ì ì²˜ë¦¬\n",
    "4. ì‹¤ì œ ë‚ ì”¨ ë°ì´í„° ì¡°íšŒ ì‹¤í–‰\n",
    "5. ê²°ê³¼ë¥¼ í‘œì¤€ í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9668e6cb-eb6d-4b73-a999-9682ab08fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_tool_calls_async(message, mcp_client):\n",
    "    if not hasattr(message, \"tool_calls\") or not message.tool_calls:\n",
    "        return []\n",
    "    \n",
    "    tool_results = []\n",
    "    for i, tool_call in enumerate(message.tool_calls):\n",
    "        try:\n",
    "            function = tool_call.function\n",
    "            function_name = getattr(function, \"name\", None)\n",
    "            arguments = getattr(function, \"arguments\", None)\n",
    "            \n",
    "            if function_name != \"get_todays_weather\":\n",
    "                continue\n",
    "            \n",
    "            city_name = None\n",
    "            if isinstance(arguments, dict):\n",
    "                city_name = arguments.get(\"city_name\")\n",
    "            elif isinstance(arguments, str):\n",
    "                try:\n",
    "                    args_dict = json.loads(arguments)\n",
    "                    city_name = args_dict.get(\"city_name\")\n",
    "                except:\n",
    "                    city_name = arguments\n",
    "            \n",
    "            if not city_name:\n",
    "                continue\n",
    "            \n",
    "            print(f\" {city_name} ë‚ ì”¨ ì¡°íšŒ ì¤‘...\")\n",
    "            result = await get_weather_mcp(mcp_client, city_name)\n",
    "            tool_call_id = getattr(tool_call, \"id\", f\"call_{i}\")\n",
    "            \n",
    "            tool_results.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(result),\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    return tool_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87b14f-9f76-46c0-b14f-2d8c159ad367",
   "metadata": {},
   "source": [
    "##  **8. ë©”ì¸ AI ì±„íŒ… í•¨ìˆ˜**\n",
    "\n",
    "ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "1. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€\n",
    "2. ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨\n",
    "3. ë‚ ì”¨ ì¿¼ë¦¬ë©´ ë„êµ¬ í˜¸ì¶œ ëª¨ë“œë¡œ ì‹¤í–‰\n",
    "4. ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ì²˜ë¦¬ í›„ ìì—°ì–´ ì‘ë‹µ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2acf9a-e069-41cc-9360-e5ffea322535",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_ai(user_message, mcp_client):\n",
    "    global conversation_history\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    try:\n",
    "        if is_weather_query(user_message):\n",
    "            print(\" ë‚ ì”¨ ë„êµ¬ ì‚¬ìš© ì¤‘...\")\n",
    "            \n",
    "            response = ollama.chat(\n",
    "                model=MODEL_NAME,\n",
    "                messages=conversation_history,\n",
    "                options={\"temperature\": 0.1},\n",
    "                tools=get_tools(),\n",
    "            )\n",
    "            \n",
    "            message = response[\"message\"]\n",
    "            \n",
    "            if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "                tool_results = await process_tool_calls_async(message, mcp_client)\n",
    "                \n",
    "                if tool_results:\n",
    "                    assistant_message = {\"role\": \"assistant\", \"content\": message.content or \"\"}\n",
    "                    if hasattr(message, \"tool_calls\"):\n",
    "                        tool_calls_data = []\n",
    "                        for tc in message.tool_calls:\n",
    "                            if hasattr(tc, \"function\"):\n",
    "                                tool_calls_data.append({\n",
    "                                    \"id\": getattr(tc, \"id\", \"unknown\"),\n",
    "                                    \"type\": \"function\",\n",
    "                                    \"function\": {\n",
    "                                        \"name\": tc.function.name,\n",
    "                                        \"arguments\": tc.function.arguments,\n",
    "                                    },\n",
    "                                })\n",
    "                        assistant_message[\"tool_calls\"] = tool_calls_data\n",
    "                    \n",
    "                    conversation_history.append(assistant_message)\n",
    "                    \n",
    "                    for result in tool_results:\n",
    "                        conversation_history.append(result)\n",
    "                    \n",
    "                    final_response = ollama.chat(\n",
    "                        model=MODEL_NAME,\n",
    "                        messages=conversation_history,\n",
    "                        options={\"temperature\": 0.7},\n",
    "                    )\n",
    "                    \n",
    "                    final_content = final_response[\"message\"][\"content\"]\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                    return final_content\n",
    "                else:\n",
    "                    content = message.content or \"ì£„ì†¡í•©ë‹ˆë‹¤. ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                    return content\n",
    "            else:\n",
    "                content = message.content or \"êµ¬ì²´ì ì¸ ë„ì‹œëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "                conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=conversation_history,\n",
    "            options={\"temperature\": 0.7},\n",
    "        )\n",
    "        \n",
    "        content = response[\"message\"][\"content\"]\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"ì˜¤ë¥˜: {str(e)}\"\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94ffa5-32e1-4633-a080-ef36490c2896",
   "metadata": {},
   "source": [
    "##  **9. ê¸°ë³¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„**\n",
    "\n",
    "ì‚¬ìš©ìì™€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ê¸°ëŠ¥:**\n",
    "- MCP ì—°ê²°: `http://localhost:8005/sse`ë¡œ ë‚ ì”¨ ì„œë²„ ì—°ê²°\n",
    "- ëª…ë ¹ì–´ ì²˜ë¦¬: quit/clear ë“±\n",
    "- ì‹¤ì‹œê°„ ëŒ€í™” ë° ì—ëŸ¬ ë³µêµ¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57750265-7447-4dea-8a96-583af08b079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_chat():\n",
    "    print(\" ë‚ ì”¨ AI ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    print(\"ì¢…ë£Œ: 'quit' | ì´ˆê¸°í™”: 'clear'\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8005/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        }\n",
    "    ) as client:\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\" ë‹¹ì‹ : \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:\n",
    "                    print(\"í”„ë¡œê·¸ë¨ ì¢…ë£Œ\")\n",
    "                    break\n",
    "                \n",
    "                if user_input.lower() in ['clear', 'ì´ˆê¸°í™”']:\n",
    "                    global conversation_history\n",
    "                    conversation_history = []\n",
    "                    print(\" ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”ë¨\")\n",
    "                    continue\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                response = await chat_with_ai(user_input, client)\n",
    "                print(f\" AI: {response}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n í”„ë¡œê·¸ë¨ ì¢…ë£Œ\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\" ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255011f-6f5c-447e-b059-5627b35207b5",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac77319-2659-43b8-b8ce-6d65bf4b6e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë‚ ì”¨ AI ì–´ì‹œìŠ¤í„´íŠ¸\n",
      "ì¢…ë£Œ: 'quit' | ì´ˆê¸°í™”: 'clear'\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ë‹¹ì‹ :  ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë‚ ì”¨ ë„êµ¬ ì‚¬ìš© ì¤‘...\n",
      " ì„œìš¸ ë‚ ì”¨ ì¡°íšŒ ì¤‘...\n",
      " AI: ì„œìš¸ì˜ í˜„ì¬ ê¸°ìƒì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "*   ê¸°ì˜¨: 10ë„\n",
      "*   ìŠµë„: 60%\n",
      "*   ë¹„/ëˆˆ: ì—†ìŒ\n",
      "*   ë°”ëŒ: ì•½í•œ ë°”ëŒì´å¹ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê¸°ìƒ ì¡°ê±´ì€ í•­ì‹œ ì—…ë°ì´íŠ¸ ë˜ë¯€ë¡œ ì •í™•ë„ê°€ ìœ ì§€ë©ë‹ˆë‹¤.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ë‹¹ì‹ :  Tell me the weather in Seoul today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë‚ ì”¨ ë„êµ¬ ì‚¬ìš© ì¤‘...\n",
      " Seoul ë‚ ì”¨ ì¡°íšŒ ì¤‘...\n",
      " AI: ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ì£¼ë¡œ êµ¬ë¦„ì´ ë‚´ë¦¬ëŠ” í˜•íƒœì…ë‹ˆë‹¤.\n",
      "ê¸°ì˜¨ì€ 32ë„ì´ë©°, ìŠµë„ëŠ” 71%ì— ë¶ˆê³¼í•©ë‹ˆë‹¤.\n",
      "í’í–¥ì€ ì„œë‚¨ì„œìª½ì´ê³ , í’ì†ì€ ì•½í•œ ë°”ëŒìœ¼ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤.\n",
      "ëŒ€ê¸° ì••ë ¥ì€ 1011hPaì´ë©°, ëŒ€ê¸° ê°€ì‹œì„±ì€ 10kmì…ë‹ˆë‹¤.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ë‹¹ì‹ :  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¡œê·¸ë¨ ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°”ë¡œ ì±„íŒ… ì‹œì‘\n",
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(start_chat())\n",
    "except:\n",
    "    asyncio.run(start_chat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e70d1-2078-470d-a01c-8df304c6016d",
   "metadata": {},
   "source": [
    "##  **10. ì–¸ì–´ ê°ì§€ ì‹œìŠ¤í…œ**\n",
    "\n",
    "ì…ë ¥ í…ìŠ¤íŠ¸ê°€ í•œêµ­ì–´ì¸ì§€ ì˜ì–´ì¸ì§€ ìë™ìœ¼ë¡œ ê°ì§€í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "**ê°ì§€ ì•Œê³ ë¦¬ì¦˜:**\n",
    "1. í•œêµ­ì–´ ë¬¸ì ë²”ìœ„ ê²€ì‚¬ (ê°€-í£)\n",
    "2. ì „ì²´ ë¬¸ì ì¤‘ í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚°\n",
    "3. 30% ì´ìƒì´ë©´ í•œêµ­ì–´ë¡œ íŒë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564576d9-8b7f-4838-9446-3c0a3c1d6faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?' -> korean\n",
      "'What's the weather in Seoul?' -> english\n",
      "'ì˜¤ëŠ˜ ë¹„ ì™€?' -> korean\n",
      "'Is it raining today?' -> english\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.llms import Ollama as OllamaLLM\n",
    "\n",
    "# í•œêµ­ì–´ ë²ˆì—­ìš© ëª¨ë¸ (í•œêµ­ì–´ë¥¼ ì˜ ì´í•´í•˜ëŠ” ëª¨ë¸)\n",
    "korean_llm = OllamaLLM(model=\"exaone3.5:7.8b\", temperature=0)\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ê°€ í•œêµ­ì–´ì¸ì§€ ì˜ì–´ì¸ì§€ ê°ì§€\"\"\"\n",
    "    korean_chars = re.findall(r'[ê°€-í£]', text)\n",
    "    total_chars = len(re.findall(r'[a-zA-Zê°€-í£]', text))\n",
    "    \n",
    "    if total_chars == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    korean_ratio = len(korean_chars) / total_chars\n",
    "    return \"korean\" if korean_ratio > 0.3 else \"english\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•´ë³´ê¸°\n",
    "test_texts = [\n",
    "    \"ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",\n",
    "    \"What's the weather in Seoul?\",\n",
    "    \"ì˜¤ëŠ˜ ë¹„ ì™€?\",\n",
    "    \"Is it raining today?\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    lang = detect_language(text)\n",
    "    print(f\"'{text}' -> {lang}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ca9ea-01f7-4635-8258-80cb7ad949fe",
   "metadata": {},
   "source": [
    "## **11. í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ ì‹œìŠ¤í…œ**\n",
    "\n",
    "í•œêµ­ì–´ ì…ë ¥ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì˜ì–´ ê¸°ë°˜ AI ëª¨ë¸ê³¼ ì†Œí†µí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9890c9c-b004-4ee0-877f-fa83b5c6a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë²ˆì—­ ì¤‘: 'ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?'\n",
      " ë²ˆì—­ ê²°ê³¼: 'What's the weather like in Seoul?'\n",
      "----------------------------------------\n",
      " ë²ˆì—­ ì¤‘: 'ë‚´ì¼ ë¹„ ì˜¬ê¹Œ?'\n",
      " ë²ˆì—­ ê²°ê³¼: 'Will it rain tomorrow?'\n",
      "----------------------------------------\n",
      " ë²ˆì—­ ì¤‘: 'ë¶€ì‚° ê¸°ì˜¨ì´ ì–¼ë§ˆì•¼?'\n",
      " ë²ˆì—­ ê²°ê³¼: 'What's the temperature in Busan?'\n",
      "----------------------------------------\n",
      " ë²ˆì—­ ì¤‘: 'ì˜¤ëŠ˜ ìš°ì‚° ê°€ì ¸ê°€ì•¼ í•´?'\n",
      " ë²ˆì—­ ê²°ê³¼: 'Should I bring an umbrella today?'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_to_english(korean_text):\n",
    "    \"\"\"í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ì˜ì–´ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "í•œêµ­ì–´: {korean_text}\n",
    "ì˜ì–´:\"\"\"\n",
    "        \n",
    "        print(f\" ë²ˆì—­ ì¤‘: '{korean_text}'\")\n",
    "        english_translation = korean_llm.invoke(prompt).strip()\n",
    "        print(f\" ë²ˆì—­ ê²°ê³¼: '{english_translation}'\")\n",
    "        return english_translation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ë²ˆì—­ ì˜¤ë¥˜: {e}\")\n",
    "        return korean_text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•´ë³´ê¸°\n",
    "korean_questions = [\n",
    "    \"ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",\n",
    "    \"ë‚´ì¼ ë¹„ ì˜¬ê¹Œ?\",\n",
    "    \"ë¶€ì‚° ê¸°ì˜¨ì´ ì–¼ë§ˆì•¼?\",\n",
    "    \"ì˜¤ëŠ˜ ìš°ì‚° ê°€ì ¸ê°€ì•¼ í•´?\"\n",
    "]\n",
    "\n",
    "for q in korean_questions:\n",
    "    translate_to_english(q)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4725e-a677-4aa7-af5d-68505643ae03",
   "metadata": {},
   "source": [
    "##  **12. ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­ ì‹œìŠ¤í…œ**\n",
    "\n",
    "AI ì‘ë‹µì„ í•œêµ­ì–´ ì‚¬ìš©ìê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë²ˆì—­í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "465b7316-cebb-4c8d-b38b-da7c286bc095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­: 'The weather in Seoul is sunny with a temperature of 25Â°C.' â†’ 'ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ê³  ê¸°ì˜¨ì´ 25Â°Cì…ë‹ˆë‹¤.'\n",
      "----------------------------------------\n",
      " ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­: 'It will rain tomorrow afternoon.' â†’ 'ë‚´ì¼ ì˜¤í›„ì— ë¹„ê°€ ì˜¬ ê±°ì˜ˆìš”.'\n",
      "----------------------------------------\n",
      " ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­: 'The current temperature in Busan is 28Â°C.' â†’ 'ë¶€ì‚°ì˜ í˜„ì¬ ê¸°ì˜¨ì€ 28Â°Cì…ë‹ˆë‹¤.'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_to_korean(english_text):\n",
    "    \"\"\"ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (AI ì‘ë‹µìš©)\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"ë‹¤ìŒ ì˜ì–´ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ í•œêµ­ì–´ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "ì˜ì–´: {english_text}\n",
    "í•œêµ­ì–´:\"\"\"\n",
    "        \n",
    "        korean_translation = korean_llm.invoke(prompt).strip()\n",
    "        print(f\" ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­: '{english_text}' â†’ '{korean_translation}'\")\n",
    "        return korean_translation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ë²ˆì—­ ì˜¤ë¥˜: {e}\")\n",
    "        return english_text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•´ë³´ê¸°\n",
    "english_responses = [\n",
    "    \"The weather in Seoul is sunny with a temperature of 25Â°C.\",\n",
    "    \"It will rain tomorrow afternoon.\",\n",
    "    \"The current temperature in Busan is 28Â°C.\"\n",
    "]\n",
    "\n",
    "for response in english_responses:\n",
    "    translate_to_korean(response)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171a0c8-4867-4895-8940-45399d2ffccb",
   "metadata": {},
   "source": [
    "##  **13. ë²ˆì—­ ì§€ì› ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**\n",
    "\n",
    "ë‹¤êµ­ì–´ ë²ˆì—­ ê¸°ëŠ¥ì´ í†µí•©ëœ ì™„ì„±í˜• ì±„íŒ… ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "- ğŸ‡°ğŸ‡·/ğŸ‡ºğŸ‡¸ ì–¸ì–´ ê°ì§€ ë° í‘œì‹œ\n",
    "- ì‹¤ì‹œê°„ ë²ˆì—­ ì§„í–‰ ìƒí™© í‘œì‹œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039f8bf4-3860-4447-bbb7-af8ffec96626",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_ai(user_message, mcp_client):\n",
    "    global conversation_history\n",
    "    \n",
    "    original_message = user_message\n",
    "    detected_lang = detect_language(user_message)\n",
    "    \n",
    "    if detected_lang == \"korean\":\n",
    "        print(\"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ê°ì§€! ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤...\")\n",
    "        user_message = translate_to_english(user_message)\n",
    "    else:\n",
    "        print(\"ğŸ‡ºğŸ‡¸ ì˜ì–´ ì…ë ¥ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    try:\n",
    "        if is_weather_query(original_message):  # ì›ë³¸ ë©”ì‹œì§€ë¡œ ë‚ ì”¨ ì¿¼ë¦¬ íŒë‹¨\n",
    "            print(\"ğŸ”§ ë‚ ì”¨ ë„êµ¬ ì‚¬ìš© ì¤‘...\")\n",
    "            \n",
    "            response = ollama.chat(\n",
    "                model=MODEL_NAME,\n",
    "                messages=conversation_history,\n",
    "                options={\"temperature\": 0.1},\n",
    "                tools=get_tools(),\n",
    "            )\n",
    "            \n",
    "            message = response[\"message\"]\n",
    "            \n",
    "            if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "                tool_results = await process_tool_calls_async(message, mcp_client)\n",
    "                \n",
    "                if tool_results:\n",
    "                    assistant_message = {\"role\": \"assistant\", \"content\": message.content or \"\"}\n",
    "                    if hasattr(message, \"tool_calls\"):\n",
    "                        tool_calls_data = []\n",
    "                        for tc in message.tool_calls:\n",
    "                            if hasattr(tc, \"function\"):\n",
    "                                tool_calls_data.append({\n",
    "                                    \"id\": getattr(tc, \"id\", \"unknown\"),\n",
    "                                    \"type\": \"function\",\n",
    "                                    \"function\": {\n",
    "                                        \"name\": tc.function.name,\n",
    "                                        \"arguments\": tc.function.arguments,\n",
    "                                    },\n",
    "                                })\n",
    "                        assistant_message[\"tool_calls\"] = tool_calls_data\n",
    "                    \n",
    "                    conversation_history.append(assistant_message)\n",
    "                    \n",
    "                    for result in tool_results:\n",
    "                        conversation_history.append(result)\n",
    "                    \n",
    "                    final_response = ollama.chat(\n",
    "                        model=MODEL_NAME,\n",
    "                        messages=conversation_history,\n",
    "                        options={\"temperature\": 0.7},\n",
    "                    )\n",
    "                    \n",
    "                    final_content = final_response[\"message\"][\"content\"]\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                    \n",
    "                    #  ìƒˆë¡œìš´ ê¸°ëŠ¥: í•œêµ­ì–´ë¡œ ì§ˆë¬¸í–ˆìœ¼ë©´ ë‹µë³€ë„ í•œêµ­ì–´ë¡œ ë²ˆì—­\n",
    "                    if detected_lang == \"korean\":\n",
    "                        print(\"ğŸ‡°ğŸ‡· ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤...\")\n",
    "                        final_content = translate_to_korean(final_content)\n",
    "                    \n",
    "                    return final_content\n",
    "                else:\n",
    "                    content = message.content or \"Sorry, I couldn't get weather information.\"\n",
    "                    if detected_lang == \"korean\":\n",
    "                        content = translate_to_korean(content)\n",
    "                    conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                    return content\n",
    "            else:\n",
    "                content = message.content or \"Please provide a specific city name.\"\n",
    "                if detected_lang == \"korean\":\n",
    "                    content = translate_to_korean(content)\n",
    "                conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "        \n",
    "        # ì¼ë°˜ ëŒ€í™”\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=conversation_history,\n",
    "            options={\"temperature\": 0.7},\n",
    "        )\n",
    "        \n",
    "        content = response[\"message\"][\"content\"]\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ê¸°ëŠ¥: í•œêµ­ì–´ë¡œ ì§ˆë¬¸í–ˆìœ¼ë©´ ë‹µë³€ë„ í•œêµ­ì–´ë¡œ ë²ˆì—­\n",
    "        if detected_lang == \"korean\":\n",
    "            print(\"ğŸ‡°ğŸ‡· ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤...\")\n",
    "            content = translate_to_korean(content)\n",
    "        \n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"ì˜¤ë¥˜: {str(e)}\"\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbf4e6-1e6b-4b71-bd40-f9cf79d2070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_chat():\n",
    "    print(\"ë²ˆì—­ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ë‚ ì”¨ AI ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    print(\"ì¢…ë£Œ: 'quit' | ì´ˆê¸°í™”: 'clear'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8005/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        }\n",
    "    ) as client:\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\" ë‹¹ì‹ : \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:\n",
    "                    print(\" í”„ë¡œê·¸ë¨ ì¢…ë£Œ\")\n",
    "                    break\n",
    "                \n",
    "                if user_input.lower() in ['clear', 'ì´ˆê¸°í™”']:\n",
    "                    global conversation_history\n",
    "                    conversation_history = []\n",
    "                    print(\" ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”ë¨\")\n",
    "                    continue\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                response = await chat_with_ai(user_input, client)\n",
    "                print(f\"ğŸ¤– AI: {response}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n í”„ë¡œê·¸ë¨ ì¢…ë£Œ\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\" ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "await start_chat()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba9b4326-c4d4-4f1d-921c-835220fb3773",
   "metadata": {},
   "source": [
    "##  **ì‹¤ìŠµ: í‚¤ì›Œë“œ í™•ì¥**\n",
    "\n",
    "í˜„ì¬ `is_weather_query()` í•¨ìˆ˜ì˜ ë‚ ì”¨ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:\n",
    "\n",
    "**í…ŒìŠ¤íŠ¸:** \"ì˜¤ëŠ˜ ìš°ì‚° ê°€ì ¸ê°€ì•¼ í•˜ë‚˜ìš”?\" ì…ë ¥ ì‹œ ë‚ ì”¨ ë„êµ¬ê°€ í™œì„±í™”ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501be259-eaaf-434e-8cc0-9391a4e92e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weather_query(text):\n",
    "    weather_keywords = [\n",
    "        \"ë‚ ì”¨\", \"ê¸°ì˜¨\", \"ì˜¨ë„\", \"ë¹„\", \"ëˆˆ\", \"ë°”ëŒ\", \"ìŠµë„\", \"ë§‘ìŒ\", \"íë¦¼\",\n",
    "        \"weather\", \"temperature\", \"rain\", \"snow\", \"wind\", \"sunny\", \"cloudy\",\n",
    "        \"ë”°ëœ»\", \"ì¶¥\", \"ë¥\", \"ì‹œì›\"\n",
    "        # ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš”:\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in weather_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46712241-5e17-49f9-bafb-f77f37885d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ ë²ˆì—­ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ë‚ ì”¨ AI ì–´ì‹œìŠ¤í„´íŠ¸\n",
      "âœ… í•œêµ­ì–´/ì˜ì–´ ëª¨ë‘ ì§€ì›!\n",
      "ì¢…ë£Œ: 'quit' | ì´ˆê¸°í™”: 'clear'\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ë‹¹ì‹ :  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘‹ í”„ë¡œê·¸ë¨ ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "#í…ŒìŠ¤íŠ¸\n",
    "await start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4275859-cb68-421f-8240-93bd6f924ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca256e0-b749-4df5-abb2-389b31caae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
